+++
title = 'DEFY - Defensive Enforcer For Your security'
date = 2024-06-14T20:08:48+02:00
+++
## Motivation
In the era of rapidly advancing artificial intelligence (AI) and machine learning (ML), ensuring the robustness and security of models against adversarial attacks is of paramount importance. Adversarial attacks, which involve deliberately crafted inputs designed to deceive models, pose significant threats to the reliability and integrity of AI systems. Traditional security measures often fall short in addressing these sophisticated threats comprehensively. Therefore, a holistic approach to model security, adversarial attack, and defence is essential for developing resilient AI systems.


## Works carried out
### Key contributions
Library for comprehensive security
- Attacks on classical models
- Attacks on LLM models
- Defence against attacks

Effectiveness of implemented methods confirmed by tests
### Tested attacks algorithms

| Name              | Source                                                                                                                 |
| ----------------- | ---------------------------------------------------------------------------------------------------------------------- |
| TextFooler        | [paper](https://arxiv.org/abs/1907.11932)                                                                              |
| TextBugger        | [paper](https://arxiv.org/abs/1812.05271)                                                                              |
| WordNetTextFooler | [paper](https://www.researchgate.net/publication/374307223_Do_Not_Trust_Me_Explainability_Against_Text_Classification) |
| BertAttack        | [paper](https://arxiv.org/abs/2004.09984)                                                                              |
### Tested detection algorithms

| Name                                | Source                                    |
| ----------------------------------- | ----------------------------------------- |
| Frequency-Guided Word Substitutions | [paper](https://arxiv.org/abs/2004.05887) |
| Masked Language Model Detection     | [paper](https://arxiv.org/abs/2304.08767) |
| VoteTRANS                           | [paper](https://arxiv.org/abs/2306.01273) |

## Results


## Important links

- Link to our [poster](https://www.canva.com/design/DAGIGEFiN18/61h6QSBN1OL3C_ZQENgDOA/view?utm_content=DAGIGEFiN18&utm_campaign=designshare&utm_medium=link&utm_source=editor)
- Link to our presentation
- Link to our [repository](https://github.com/DEFY-AI/defy)



